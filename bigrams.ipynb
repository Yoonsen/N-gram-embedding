{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b28516b-6daf-4aaa-8d19-07a984c4f5a0",
   "metadata": {},
   "source": [
    "# Utprøving\n",
    "\n",
    "Bare lag kopier av notebooken for å gjøre nye vinklinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8494ffe4-c68b-444a-80ed-e1b70de18be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhlab as dh\n",
    "from IPython.display import HTML, Markdown\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0789b79-f657-4c6b-808b-de662d9512a9",
   "metadata": {},
   "source": [
    "dh.css - gir fin styling (men ikke alle er enig, så bare slett eller gi et filargument om du har en egen css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34a3a782-5bc3-4219-a848-cba788b9b482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url(http://fonts.googleapis.com/css?family=Lato|Philosopher|Montserrat|Source+Code+Pro|Merriweather|Shippori+Mincho|Istok+Web|Philosopher|Assistant:200,400,700);\n",
       "\n",
       "p {\n",
       "    font-size:1.3em;\n",
       "    font-family:serif;\n",
       "    line-height:1.4em;\n",
       "    color:#142850;\n",
       "}\n",
       "h1, h2, h3, h4 {\n",
       "    color:#27496d;\n",
       "}\n",
       "\n",
       "/*\n",
       ".prompt, .jp-InputPrompt, .jp-InputArea-prompt, .jp-OutputPrompt, .jp-OutputArea-prompt {\n",
       "    visibility: hidden; \n",
       "}\n",
       "\n",
       "\n",
       ".jp-CodeCell .jp-Notebook-cell    {\n",
       "    margin-left:10%;\n",
       "    margin-right:5%;\n",
       "}\n",
       "\n",
       "\n",
       ".jp-InputArea, .jp-OutputArea {\n",
       "    margin-left:2.5em;\n",
       "    margin-right:2.5em;\n",
       "}\n",
       "*/\n",
       "\n",
       "\n",
       "body  {\n",
       "    margin:10%;\n",
       "    counter-reset: h1counter;\n",
       "\n",
       "}\n",
       "\n",
       "/* .jp-MarkdownOutput, .text_cell_render {\n",
       "\n",
       "    background-color:#FEFBF1;    \n",
       "    border-style: solid;\n",
       "    border-width: 1px;\n",
       "    border-color: rgba(0,0,0, 0.10);;\n",
       "} */\n",
       "\n",
       "\n",
       "h1:after {\n",
       "    content: \"\"; /* This is necessary for the pseudo element to work. */ \n",
       "    display: block; /* This will put the pseudo element on its own line. */\n",
       "    /*margin: 0 auto; This will center the border. */\n",
       "    width: 50%; /* Change this to whatever width you want. */\n",
       "    padding-top: 10px;\n",
       "    border-bottom:3px solid SlateGray; /* FireBrick; */\n",
       "}\n",
       "\n",
       "h2:after {\n",
       "    content: \"\"; /* This is necessary for the pseudo element to work. */ \n",
       "    display: block; /* This will put the pseudo element on its own line. */\n",
       "    /*margin: 0 auto; This will center the border. */\n",
       "    width: 30%; /* Change this to whatever width you want. */\n",
       "    padding-top: 10px;\n",
       "    border-bottom:2px solid SlateGray; /* FireBrick; */\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh.css()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97963071-3575-4fc8-9278-23d39f701e84",
   "metadata": {},
   "source": [
    "## Filplasseringer\n",
    "\n",
    "N-grammene ligger ferdig indeksert. Men det her er bigrammer fra 2015, i dag har vi fler. De er lastet ned på en annen disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7378c574-ac59-42ce-8025-a76c4600b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_root = \"/mnt/disk4/NB-ngram-assoc/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5f87e3-6960-4d95-8950-cbe3889aa42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = \"/mnt/disk4/NB-ngram-assoc/unigram-one-row.db\"\n",
    "bi = \"/mnt/disk4/NB-ngram-assoc/bigram-one-row.db\"\n",
    "tri = \"/mnt/disk4/NB-ngram-assoc/trigram-one-row.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b137210-2317-4027-ac12-4e7b68b45535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(db, sql, params=()):\n",
    "    with sqlite3.connect(db) as con:\n",
    "        cur = con.cursor()\n",
    "        res = cur.execute(sql, params).fetchall()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c811f1-2a82-4659-98f3-d85ead37ee52",
   "metadata": {},
   "source": [
    "Spørringer kan gjøres med ```query```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48207bbc-b81e-436d-85e9-322368b35a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('table',\n",
       "  'bigram',\n",
       "  'bigram',\n",
       "  2,\n",
       "  'CREATE TABLE bigram (freq int, lang varchar, first varchar, second varchar, json text, assoc float, pmi float)'),\n",
       " ('index',\n",
       "  '_lfsf_',\n",
       "  'bigram',\n",
       "  5854348,\n",
       "  'CREATE INDEX _lfsf_ on bigram (lang,first,second,freq)')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(bi, \"select * from sqlite_master limit 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "933eac9c-b0fe-4f12-b989-a4ec4efbe947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jærbuer', 'spiser', 'kirsebær', 23.55522887335257, 13),\n",
       " ('Overfallsmenn', 'spiser', 'ikke', 20.609993505366152, 11),\n",
       " ('nøden', 'spiser', 'fanden', 20.05728960628191, 83),\n",
       " ('sekstiåttere', 'spiser', 'ikke', 18.693989407879293, 69),\n",
       " ('frokost', 'spiser', 'Vilde', 18.537601256676304, 113),\n",
       " ('Hvorfor', 'spiser', 'mesteren', 17.25426539638431, 13),\n",
       " ('konkurransedagen', 'spiser', 'jeg', 17.05598532838897, 10),\n",
       " ('Hva', 'spiser', 'fiskene', 16.108569299517168, 10),\n",
       " ('Vi', 'spiser', 'frokost', 15.824185530260493, 167),\n",
       " ('Hege', 'spiser', 'ett', 15.498541255648027, 13)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(tri, \"select first, second,third, assoc, freq from trigram where lang='nob' and second = 'spiser'  order by assoc desc limit 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc5c04-8ae2-41d8-917b-9a73d61e3f6b",
   "metadata": {},
   "source": [
    "## Kode for å lage matrisen\n",
    "\n",
    "Her er kode for å lage matriser. Under er det satt opp kode for venstre og så mot høyre, altså at høyre kontekst er alle ord til høyre for $a$, som i $\\{x|\\beta(a, x)\\}$ der$\\beta$ koder bigrambasen, og venstre er alle til venstre $\\{x|\\beta(x, a)\\}$. All spørringen gjøres mot sqlite-basen, og vi lager terskelverdier på frekvens og pmi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132f211-0189-4032-bc1e-8f07d7a105cc",
   "metadata": {},
   "source": [
    "## Sparse matrix \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dfab03-5af0-4502-8141-f55aef8aa490",
   "metadata": {},
   "source": [
    "### Versjon med ord før og etter\n",
    "\n",
    "for et gitt ord samles både ordet før og ordet etter for å lage matrisen sånn for _løpe_ vil både _å_ og _fort_ bli med med utgangspunkt i _å løpe_ og _løpe fort_\n",
    "\n",
    "koden returnerer et par av (matrise, ordindeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df8d3b6c-da79-4b90-a3f5-f24180504b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse_matrix(db_path, vocab_size=500000):\n",
    "   from scipy.sparse import csr_matrix\n",
    "   import numpy as np\n",
    "   \n",
    "   rows = []\n",
    "   cols = []\n",
    "   data = []\n",
    "   \n",
    "   with sqlite3.connect(db_path) as conn:\n",
    "       cur = conn.cursor()\n",
    "       \n",
    "       # Create temporary table for vocabulary\n",
    "       print(\"Creating temporary vocabulary table...\")\n",
    "       cur.execute(\"\"\"\n",
    "           CREATE TEMP TABLE top_words AS\n",
    "           SELECT first as word, SUM(freq) as total_freq \n",
    "           FROM bigram \n",
    "           WHERE lang='nob'\n",
    "           GROUP BY first \n",
    "           ORDER BY total_freq DESC \n",
    "           LIMIT ?\n",
    "       \"\"\", (vocab_size,))\n",
    "       \n",
    "       # Create index on the temporary table\n",
    "       cur.execute(\"CREATE INDEX idx_top_words ON top_words(word)\")\n",
    "       \n",
    "       # Get word to index mapping\n",
    "       print(\"Creating vocabulary mapping...\")\n",
    "       word_to_idx = {word: idx for idx, (word, freq) \n",
    "                     in enumerate(cur.execute(\"SELECT word, total_freq FROM top_words\"))}\n",
    "       \n",
    "       # Stream bigrams with fixed column references\n",
    "       print(\"Streaming bigrams...\")\n",
    "       cur.execute(\"\"\"\n",
    "           SELECT b.first, b.second, b.pmi \n",
    "           FROM bigram b\n",
    "           JOIN top_words w1 ON b.first = w1.word\n",
    "           JOIN top_words w2 ON b.second = w2.word\n",
    "           WHERE b.lang='nob'\n",
    "       \"\"\")\n",
    "       \n",
    "       count = 0\n",
    "       while True:\n",
    "           chunk = cur.fetchmany(10000)\n",
    "           if not chunk:\n",
    "               break\n",
    "               \n",
    "           for first, second, pmi in chunk:\n",
    "               # Add right context\n",
    "               rows.append(word_to_idx[first])\n",
    "               cols.append(word_to_idx[second])\n",
    "               data.append(pmi)\n",
    "               \n",
    "               # Add left context for the same bigram\n",
    "               rows.append(word_to_idx[second])\n",
    "               cols.append(word_to_idx[first])\n",
    "               data.append(pmi)\n",
    "           \n",
    "           count += len(chunk)\n",
    "           if count % 2000000 == 0:\n",
    "               print(f\"Processed {count} bigrams...\")\n",
    "   \n",
    "   print(\"Creating sparse matrix...\")\n",
    "   matrix = csr_matrix((data, (rows, cols)), shape=(len(word_to_idx), len(word_to_idx)))\n",
    "   return matrix, word_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2225cbf-c9fb-4cd0-ab1c-500f71ef21ed",
   "metadata": {},
   "source": [
    "Lag matrise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2db6d0d4-ed83-4a83-82fb-bed42144aaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary vocabulary table...\n",
      "Creating vocabulary mapping...\n",
      "Streaming bigrams...\n",
      "Processed 2000000 bigrams...\n",
      "Processed 4000000 bigrams...\n",
      "Processed 6000000 bigrams...\n",
      "Processed 8000000 bigrams...\n",
      "Processed 10000000 bigrams...\n",
      "Processed 12000000 bigrams...\n",
      "Processed 14000000 bigrams...\n",
      "Creating sparse matrix...\n"
     ]
    }
   ],
   "source": [
    "matrix, word_to_idx = create_sparse_matrix(bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a31f8-b632-455b-b8b5-91a0970c148a",
   "metadata": {},
   "source": [
    "### Versjoner for høyre- og venstrekontekst\n",
    "\n",
    "For et gitt ord samles sammen ordene som kommer etter, eller høyrekontekst, og så ordene som kommer foran eller venstrekontekst.\n",
    "\n",
    "Så for _kaffe_ for vi et eget sett for _sterk kaffe_ og ett sett for _kaffe med_, men både _sterk_ og _med_ kan forekomme på hver sin side.\n",
    "\n",
    "koden beregner begge og returnerer et trippen av \n",
    "(venstrematrise, høyrematrise, ordindeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a12e2c5-1701-4147-8a96-1f464a8618cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_matrices(db_path, vocab_size=500000):\n",
    "    from scipy.sparse import csr_matrix\n",
    "    import numpy as np\n",
    "    \n",
    "    # Separate lists for left and right contexts\n",
    "    left_rows, left_cols, left_data = [], [], []  # for (x, target) pairs\n",
    "    right_rows, right_cols, right_data = [], [], []  # for (target, x) pairs\n",
    "    \n",
    "    with sqlite3.connect(db_path) as conn:\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        # Create temporary vocabulary table (same as before)\n",
    "        print(\"Creating temporary vocabulary table...\")\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TEMP TABLE top_words AS\n",
    "            SELECT first as word, SUM(freq) as total_freq \n",
    "            FROM bigram \n",
    "            WHERE lang='nob'\n",
    "            GROUP BY first \n",
    "            ORDER BY total_freq DESC \n",
    "            LIMIT ?\n",
    "        \"\"\", (vocab_size,))\n",
    "        \n",
    "        cur.execute(\"CREATE INDEX idx_top_words ON top_words(word)\")\n",
    "        \n",
    "        # Get word to index mapping\n",
    "        print(\"Creating vocabulary mapping...\")\n",
    "        word_to_idx = {word: idx for idx, (word, freq) \n",
    "                      in enumerate(cur.execute(\"SELECT word, total_freq FROM top_words\"))}\n",
    "        \n",
    "        # Stream bigrams and separate into left/right contexts\n",
    "        print(\"Streaming bigrams...\")\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT b.first, b.second, b.pmi \n",
    "            FROM bigram b\n",
    "            JOIN top_words w1 ON b.first = w1.word\n",
    "            JOIN top_words w2 ON b.second = w2.word\n",
    "            WHERE b.lang='nob'\n",
    "        \"\"\")\n",
    "        \n",
    "        count = 0\n",
    "        while True:\n",
    "            chunk = cur.fetchmany(10000)\n",
    "            if not chunk:\n",
    "                break\n",
    "                \n",
    "            for first, second, pmi in chunk:\n",
    "                # (first, second) represents right context for 'first'\n",
    "                right_rows.append(word_to_idx[first])\n",
    "                right_cols.append(word_to_idx[second])\n",
    "                right_data.append(pmi)\n",
    "                \n",
    "                # (first, second) represents left context for 'second'\n",
    "                left_rows.append(word_to_idx[second])  # target word\n",
    "                left_cols.append(word_to_idx[first])   # context word\n",
    "                left_data.append(pmi)\n",
    "            \n",
    "            count += len(chunk)\n",
    "            if count % 3000000 == 0:\n",
    "                print(f\"Processed {count} bigrams...\")\n",
    "    \n",
    "    print(\"Creating sparse matrices...\")\n",
    "    # Matrix where rows are target words and columns are left context words\n",
    "    left_matrix = csr_matrix((left_data, (left_rows, left_cols)), \n",
    "                           shape=(len(word_to_idx), len(word_to_idx)))\n",
    "    \n",
    "    # Matrix where rows are target words and columns are right context words\n",
    "    right_matrix = csr_matrix((right_data, (right_rows, right_cols)), \n",
    "                            shape=(len(word_to_idx), len(word_to_idx)))\n",
    "    \n",
    "    return left_matrix, right_matrix, word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf7be102-0377-4849-8920-79adeed5d44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary vocabulary table...\n",
      "Creating vocabulary mapping...\n",
      "Streaming bigrams...\n",
      "Processed 1000000 bigrams...\n",
      "Processed 2000000 bigrams...\n",
      "Processed 3000000 bigrams...\n",
      "Processed 4000000 bigrams...\n",
      "Processed 5000000 bigrams...\n",
      "Processed 6000000 bigrams...\n",
      "Processed 7000000 bigrams...\n",
      "Processed 8000000 bigrams...\n",
      "Processed 9000000 bigrams...\n",
      "Processed 10000000 bigrams...\n",
      "Processed 11000000 bigrams...\n",
      "Processed 12000000 bigrams...\n",
      "Processed 13000000 bigrams...\n",
      "Processed 14000000 bigrams...\n",
      "Creating sparse matrices...\n"
     ]
    }
   ],
   "source": [
    "left, right, context_word_to_idx = create_context_matrices(bi, vocab_size=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d78c84-f888-429f-a5aa-01a94aa4b3d5",
   "metadata": {},
   "source": [
    "## Lag komprimert matrise\n",
    "\n",
    "Her bruker vi TruncatedSVD, men kan benytte andre metoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37499836-0e75-42aa-834a-ff863b1c835b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings: (500000, 200) (500000, 200)\n",
      "Explained left variance ratio: 0.29979637079691973\n",
      "Explained right variance ratio: 0.29887136580229257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Create and fit the SVD\n",
    "left_svd = TruncatedSVD(n_components=200, random_state=42)\n",
    "right_svd = TruncatedSVD(n_components=200, random_state=42)\n",
    "\n",
    "left_embeddings = left_svd.fit_transform(left)\n",
    "right_embeddings = right_svd.fit_transform(right)\n",
    "print(\"Shape of embeddings:\", left_embeddings.shape, right_embeddings.shape)\n",
    "print(\"Explained left variance ratio:\", left_svd.explained_variance_ratio_.sum())\n",
    "print(\"Explained right variance ratio:\", right_svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5fb4e84-73fc-4de1-a702-0c79974c183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings: (500000, 200)\n",
      "Explained variance ratio: 0.311545461099871\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Create and fit the SVD\n",
    "svd = TruncatedSVD(n_components=200, random_state=42)\n",
    "embeddings = svd.fit_transform(matrix)\n",
    "\n",
    "print(\"Shape of embeddings:\", embeddings.shape)\n",
    "print(\"Explained variance ratio:\", svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd1813-3806-41af-b0d8-2c3ededa34e5",
   "metadata": {},
   "source": [
    "## Lagre embeddinger\n",
    "\n",
    "Lagrer som numpy arrayer - ta bort det som ikke trengs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c152667-06a9-46a8-aca8-0edaef5f98d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cb4995d-e745-4e03-ab9c-12ffba793ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('nob_left_embeddings_bigram.npy', left_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d89c8cd9-bc95-4ded-a459-0a664f3d2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('nob_right_embeddings_bigram.npy', right_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d081977-c543-4bca-8a8f-a80a6ef39c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('nob_embeddings_bigram.npy', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad3c8841-9ae8-4380-83cd-4b577dfb6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save word to index mapping\n",
    "import json\n",
    "with open('word_to_idx_bigram.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(word_to_idx, f, ensure_ascii=False)\n",
    "import json\n",
    "with open('word_to_idx_bigram_contexts.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(context_word_to_idx, f, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb07e162-054c-4b85-b53b-6fe695f6d5bc",
   "metadata": {},
   "source": [
    "## Test embeddinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64317e30-5c93-412c-a8e8-d60cdb62e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(word, embeddings, word_to_idx, n=10):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    \n",
    "    if word not in word_to_idx:\n",
    "        return \"Word not in vocabulary\"\n",
    "    \n",
    "    word_idx = word_to_idx[word]\n",
    "    word_vector = embeddings[word_idx].reshape(1, -1)\n",
    "    \n",
    "    # Compute similarities\n",
    "    similarities = cosine_similarity(word_vector, embeddings)[0]\n",
    "    \n",
    "    # Get top N similar words (excluding the word itself)\n",
    "    most_similar = []\n",
    "    indices = similarities.argsort()[::-1][1:n+1]\n",
    "    \n",
    "    return [(list(word_to_idx.keys())[list(word_to_idx.values()).index(idx)], \n",
    "             similarities[idx]) for idx in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6fbf6-11a0-4f4d-937d-b3c363c9022a",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf47edf2-7156-4a4a-bdc6-218d3add5062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('demokrati', 0.7748139528955333),\n",
       " ('sikkerhetssystem', 0.7560614309893858),\n",
       " ('utbyggingsmønster', 0.7484329430291474),\n",
       " ('distribusjonsnett', 0.7248803844701253),\n",
       " ('samvirke', 0.7190325434001414),\n",
       " ('skolebibliotek', 0.7184723683923118),\n",
       " ('politisamarbeid', 0.7082358370995934),\n",
       " ('skatteregnskap', 0.7012121197083403),\n",
       " ('industrielt', 0.6993679135443505),\n",
       " ('forbedringsarbeid', 0.6993178306850556),\n",
       " ('tiltaksarbeid', 0.697016644089604),\n",
       " ('byråkrati', 0.6962829587107863),\n",
       " ('foreldreskap', 0.693503199578171),\n",
       " ('importvern', 0.69124670617893),\n",
       " ('kulturarbeid', 0.6904486467555324),\n",
       " ('evalueringsarbeid', 0.6886498036890953),\n",
       " ('familieliv', 0.6866255236358859),\n",
       " ('kjønnsliv', 0.6850864522081741),\n",
       " ('samhold', 0.6843587961158817),\n",
       " ('kontrollsystem', 0.6780904663097107)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest(\"folkestyre\", left_embeddings, context_word_to_idx, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c57f169d-b0ed-47d1-bcac-5d192bb0c2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('imperialisme', 0.957410742904829),\n",
       " ('ansvarslæring', 0.9562066658776511),\n",
       " ('bedriftsdemokrati', 0.9526920649674018),\n",
       " ('urbefolkning', 0.9415133284607968),\n",
       " ('immanens', 0.9408424669641113),\n",
       " ('relativitet', 0.9372458794302525),\n",
       " ('mannsarbeid', 0.9367848331240615),\n",
       " ('islamisme', 0.9324445061244013),\n",
       " ('tilbakeliggenhet', 0.932390893165072),\n",
       " ('opportunisme', 0.9308411706505932)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest(\"folkestyre\", right_embeddings, context_word_to_idx, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba0927a0-1356-4188-b925-90f8ebc0b534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fagstyre', 0.8134198609463499),\n",
       " ('foreldreskap', 0.8062806780890421),\n",
       " ('sorgarbeid', 0.793484955554102),\n",
       " ('flertallsstyre', 0.7914832581651849),\n",
       " ('bomiljø', 0.7890958154964803),\n",
       " ('medborgerskap', 0.7882201084305864),\n",
       " ('skatteregnskap', 0.7878211147804894),\n",
       " ('lokaldemokrati', 0.7829862781320682),\n",
       " ('deltakerdemokrati', 0.7788566695770515),\n",
       " ('kjønnsliv', 0.777391363323904)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest(\"folkestyre\", embeddings, word_to_idx, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2014006-0f57-45c3-b2db-7e838e652e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b210439a-ae56-4352-aa9e-9d800c54e84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('drikke', 0.8795432513950372),\n",
       " ('spille', 0.8161752586706609),\n",
       " ('sove', 0.8115023031497804),\n",
       " ('kjøpe', 0.8102030587129718),\n",
       " ('dø', 0.7905000589369365),\n",
       " ('sitte', 0.7845383675111297),\n",
       " ('leke', 0.7755767249861851),\n",
       " ('danse', 0.7684195793455394),\n",
       " ('snakke', 0.7662041866569884),\n",
       " ('vente', 0.7629548597919222)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest(\"spise\", embeddings, word_to_idx, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5eb762e6-d00c-4e99-ae75-ed76aad1d84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('drikke', 0.8708795088698218),\n",
       " ('spist', 0.8391220462918889),\n",
       " ('spiser', 0.8026804078043023),\n",
       " ('spiste', 0.7606383162441575),\n",
       " ('drukket', 0.7505574575879221),\n",
       " ('drikker', 0.7236008987434204),\n",
       " ('kjøpe', 0.7175299143798848),\n",
       " ('drakk', 0.6983177967705037),\n",
       " ('kopp', 0.683305928554896),\n",
       " ('servert', 0.6639450946358891)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest(\"spise\", right_embeddings, context_word_to_idx, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a102fca5-a449-4f5d-814c-f6cb9d1f953f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spille', 0.9642619853637652),\n",
       " ('kjøre', 0.9631011425133194),\n",
       " ('føle', 0.958907210235288),\n",
       " ('kjøpe', 0.9574394843696666),\n",
       " ('danse', 0.9534318350667251),\n",
       " ('sende', 0.9515402713713874),\n",
       " ('handle', 0.9515395980785162),\n",
       " ('øve', 0.9510206710242984),\n",
       " ('slippe', 0.9498104734017206),\n",
       " ('flytte', 0.9463676615654408)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_nearest(\"spise\", left_embeddings, context_word_to_idx, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
